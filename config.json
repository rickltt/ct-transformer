{
    "vocab_size":272833,
    "d_model": 256,
    "num_attention_heads":8,
    "max_position_embeddings":256,
    "hidden_dropout_prob":0.1,
    "attention_probs_dropout_prob":0.1,
    "layer_norm_eps":1e-12,
    "pad_token_id":0,
    "pad_label_id":-100,
    "intermediate_size":1024,
    "num_hidden_layers": 4,
    "L_N":9
}